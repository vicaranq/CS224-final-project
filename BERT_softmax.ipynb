{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e8f743-ceab-449c-9ee7-200a1785cb16",
   "metadata": {},
   "source": [
    "# Use BERT Representations with LogisticRegression Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dae3b5-f005-418c-8e46-9bd8758cf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "\n",
    "\n",
    "import dataset\n",
    "import vsm\n",
    "import sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c995c70-1ec0-47c7-be85-5a622874c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER = 2\n",
    "TWITTER_AIRLINES = 3\n",
    "TWITTER_APPLE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5059a022-607d-493b-8e7e-82937409db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_train, twitter_validate, twitter_test =  dataset.dataset_reader(TWITTER)\n",
    "[twitter_train, twitter_validate, twitter_test] = list(map(lambda ds : dataset.prune_columns(2, ds), [twitter_train, twitter_validate, twitter_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41be400-82cf-469e-96b0-522cf9de12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_weights_name = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "bert_model = BertModel.from_pretrained(bert_weights_name)\n",
    "# model = BertForSequenceClassification.from_pretrained(bert_weights_name)\n",
    "# Unique values of sentiment\n",
    "twitter_sentiment_labels = twitter_train['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23b9013-5def-4e2a-a699-3bb3b3cd984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_softmax_classifier(X, y):\n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr')\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466a1797-1ce2-4a94-b900-776777db0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_cls_phi(text):\n",
    "    # Get the ids. `vsm.hf_encode` will help; be sure to\n",
    "    # set `add_special_tokens=True`.\n",
    "    ##### YOUR CODE HERE\n",
    "    subtok_ids = vsm.hf_encode(text, bert_tokenizer, add_special_tokens=True)\n",
    "\n",
    "    # Get the BERT representations. `vsm.hf_represent` will help:\n",
    "    ##### YOUR CODE HERE\n",
    "    subtok_reps = vsm.hf_represent(subtok_ids, bert_model, layer=-1)\n",
    "\n",
    "    # Index into `reps` to get the representation above [CLS].\n",
    "    # The shape of `reps` should be (1, n, 768), where n is the\n",
    "    # number of tokens. You need the 0th element of the 2nd dim:\n",
    "    ##### YOUR CODE HERE\n",
    "    cls_rep = subtok_reps[0][:][0]\n",
    "\n",
    "    # These conversions should ensure that you can work with the\n",
    "    # representations flexibly. Feel free to change the variable\n",
    "    # name:\n",
    "    return cls_rep.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bb900e-ec8f-4e7c-92e2-987c363777e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156831, 3000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_train.size, twitter_validate.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2c69f6-6084-4316-899d-b2ec9d52d16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant      0.354     0.203     0.258       172\n",
      "    Negative      0.491     0.692     0.574       266\n",
      "     Neutral      0.528     0.432     0.475       285\n",
      "    Positive      0.543     0.574     0.558       277\n",
      "\n",
      "    accuracy                          0.501      1000\n",
      "   macro avg      0.479     0.475     0.466      1000\n",
      "weighted avg      0.492     0.501     0.487      1000\n",
      "\n",
      "CPU times: user 1h 8min 17s, sys: 58.4 s, total: 1h 9min 15s\n",
      "Wall time: 11min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_experiment1500 = sst.experiment(\n",
    "    twitter_train[:1500], # \n",
    "    hf_cls_phi,\n",
    "    fit_softmax_classifier,\n",
    "    assess_dataframes=[twitter_validate[:1000]],\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5cdd3f-d4b1-4ccd-9f65-1ddf47011ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant      0.410     0.186     0.256       172\n",
      "    Negative      0.505     0.692     0.584       266\n",
      "     Neutral      0.564     0.467     0.511       285\n",
      "    Positive      0.531     0.617     0.571       277\n",
      "\n",
      "    accuracy                          0.520      1000\n",
      "   macro avg      0.503     0.490     0.480      1000\n",
      "weighted avg      0.513     0.520     0.503      1000\n",
      "\n",
      "CPU times: user 43min 3s, sys: 24.5 s, total: 43min 28s\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_experiment3000 = sst.experiment(\n",
    "    twitter_train[:3000], # \n",
    "    hf_cls_phi,\n",
    "    fit_softmax_classifier,\n",
    "    assess_dataframes=[twitter_validate[:1000]],\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ec4292a-caa6-4f86-a98e-dd673983774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant      0.440     0.192     0.267       172\n",
      "    Negative      0.514     0.752     0.611       266\n",
      "     Neutral      0.551     0.516     0.533       285\n",
      "    Positive      0.595     0.578     0.586       277\n",
      "\n",
      "    accuracy                          0.540      1000\n",
      "   macro avg      0.525     0.509     0.499      1000\n",
      "weighted avg      0.534     0.540     0.523      1000\n",
      "\n",
      "CPU times: user 2h 38min 23s, sys: 2min 11s, total: 2h 40min 34s\n",
      "Wall time: 26min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_experiment6000 = sst.experiment(\n",
    "    twitter_train[:6000], # \n",
    "    hf_cls_phi,\n",
    "    fit_softmax_classifier,\n",
    "    assess_dataframes=[twitter_validate[:1500]],\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe91cba-a1d6-4bc5-8c0b-f2272bdee7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant      0.455     0.203     0.281       172\n",
      "    Negative      0.529     0.763     0.625       266\n",
      "     Neutral      0.591     0.547     0.568       285\n",
      "    Positive      0.622     0.617     0.620       277\n",
      "\n",
      "    accuracy                          0.565      1000\n",
      "   macro avg      0.549     0.533     0.523      1000\n",
      "weighted avg      0.559     0.565     0.548      1000\n",
      "\n",
      "CPU times: user 3h 37min 11s, sys: 2min 38s, total: 3h 39min 49s\n",
      "Wall time: 37min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_experiment12000 = sst.experiment(\n",
    "    twitter_train[:12000], # \n",
    "    hf_cls_phi,\n",
    "    fit_softmax_classifier,\n",
    "    assess_dataframes=[twitter_validate[:2000]],\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4326b274-a348-4623-a1eb-3142a2a52b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant      0.589     0.250     0.351       172\n",
      "    Negative      0.570     0.778     0.658       266\n",
      "     Neutral      0.604     0.568     0.586       285\n",
      "    Positive      0.625     0.668     0.646       277\n",
      "\n",
      "    accuracy                          0.597      1000\n",
      "   macro avg      0.597     0.566     0.560      1000\n",
      "weighted avg      0.598     0.597     0.581      1000\n",
      "\n",
      "CPU times: user 11h 53min 46s, sys: 8min 41s, total: 12h 2min 28s\n",
      "Wall time: 2h 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_experiment_full = sst.experiment(\n",
    "    twitter_train, # \n",
    "    hf_cls_phi,\n",
    "    fit_softmax_classifier,\n",
    "    assess_dataframes=[twitter_validate],\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54b31f7-4cb2-4e55-b20d-ccde15e31350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'phi', 'train_dataset', 'assess_datasets', 'predictions', 'metric', 'scores'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_experiment_full.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7bac1a5-92e3-468e-847b-e759eb09a2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5602068458394315]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_experiment_full['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0ed646-5437-43db-a2f5-7938349cea10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe_macro_f1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_experiment_full['metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95567ac1-8815-4694-96c7-dff72617250b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', solver='liblinear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_experiment_full['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccb547-1174-471f-b6e5-e9239d23fe4b",
   "metadata": {},
   "source": [
    "# Test BERT trained on Tweets on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f4d5a18-66b3-467b-aea7-59f196b07bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_bert(text):\n",
    "    # List of tokenized examples:\n",
    "    X = [bert_experiment_full['phi'](text)]\n",
    "    # Standard `predict` step on a list of lists of str:\n",
    "    preds = bert_experiment_full['model'].predict(X)\n",
    "    # Be sure to return the only member of the predictions,\n",
    "    # rather than the singleton list:\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca03e9e-f006-40a3-aa3a-681dacbac891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% time\n",
    "# twitter_test['prediction'] = twitter_test['text'].apply(predict_one_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "145568c0-81b1-485f-9cc5-8c5fcd4ed951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sst' from '/mnt/c/Users/echya/Documents/XCS224U - 007 Natural Language Understanding/CS224-final-project/sst.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09db34c2-0a98-4627-ae75-75653fdde41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant      0.481     0.268     0.344      3915\n",
      "    Negative      0.602     0.715     0.654      6725\n",
      "     Neutral      0.547     0.537     0.542      5446\n",
      "    Positive      0.579     0.632     0.604      6319\n",
      "\n",
      "    accuracy                          0.570     22405\n",
      "   macro avg      0.552     0.538     0.536     22405\n",
      "weighted avg      0.561     0.570     0.559     22405\n",
      "\n",
      "CPU times: user 2h 7min 45s, sys: 51.8 s, total: 2h 8min 37s\n",
      "Wall time: 21min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_test = sst.evaluate(\n",
    "    bert_experiment_full['model'],\n",
    "    bert_experiment_full['phi'],\n",
    "    assess_dataframes=[twitter_test],\n",
    "    vectorizer=bert_experiment_full['assess_datasets'][0]['vectorizer'],\n",
    "    vectorize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ec6d2-f389-4995-b1d9-5003bff03522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
